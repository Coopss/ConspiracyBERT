{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds\n",
    "tfds.disable_progress_bar()\n",
    "\n",
    "from official.modeling import tf_utils\n",
    "from official import nlp\n",
    "from official.nlp import bert\n",
    "\n",
    "# Load the required submodules\n",
    "import official.nlp.optimization\n",
    "import official.nlp.bert.bert_models\n",
    "import official.nlp.bert.configs\n",
    "import official.nlp.bert.run_classifier\n",
    "import official.nlp.bert.tokenization\n",
    "import official.nlp.data.classifier_data_lib\n",
    "import official.nlp.modeling.losses\n",
    "import official.nlp.modeling.models\n",
    "import official.nlp.modeling.networks\n",
    "\n",
    "# Set CPU as available physical device\n",
    "tf.config.set_visible_devices([], 'GPU')\n",
    "\n",
    "from pymongo import MongoClient\n",
    "from auth import username, password\n",
    "import urllib\n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient('mongodb://' + urllib.parse.quote_plus(username) + ':' + urllib.parse.quote_plus(password) + '@198.211.115.252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bert_config.json',\n",
       " 'BERT_LARGE_CASED',\n",
       " 'bert_model.ckpt.data-00000-of-00001',\n",
       " 'bert_model.ckpt.index',\n",
       " 'bert_model.ckpt.meta',\n",
       " 'vocab.txt',\n",
       " 'wwm_uncased_L-24_H-1024_A-16']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_folder_bert = \"C:/Users/Ryan/Desktop/projects/ConspiracyBERT/config\"\n",
    "tf.io.gfile.listdir(gs_folder_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up tokenizer to generate Tensorflow dataset\n",
    "tokenizer = bert.tokenization.FullTokenizer(\n",
    "    vocab_file=os.path.join(gs_folder_bert, \"vocab.txt\"),\n",
    "     do_lower_case=True)\n",
    "\n",
    "# print(\"Vocab size:\", len(tokenizer.vocab))\n",
    "\n",
    "# tokens = tokenizer.tokenize(\"Hello TensorFlow!\")\n",
    "# print(tokens)\n",
    "# ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "# print(ids)\n",
    "\n",
    "# tokenizer.convert_tokens_to_ids(['[CLS]', '[SEP]'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "\n",
    "conspiracies = ['chemtrails']\n",
    "for conspiracy in conspiracies:\n",
    "\n",
    "    chemcol = client[conspiracy]['hashtag_chemtrails'] #todo\n",
    "    cursor = chemcol.find({})\n",
    "    for document in cursor:\n",
    "        try:\n",
    "            data[conspiracy].append(document)\n",
    "        except:\n",
    "            data.update({conspiracy : [document]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sentence(s, tokenizer):\n",
    "   tokens = list(tokenizer.tokenize(s))\n",
    "   tokens.append('[SEP]')\n",
    "   return tokenizer.convert_tokens_to_ids(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_sentances = np.array([np.array(encode_sentence(row['text'], tokenizer)) for row in data[conspiracy] for conspiracy in conspiracies])\n",
    "\n",
    "# for conspiracy in conspiracies:\n",
    "#     conspiracy_tweets = data[conspiracy]\n",
    "#     for row in conspiracy_tweets: \n",
    "#         tokens = tokenizer.tokenize(row['text'])\n",
    "# #         print(tokens)\n",
    "#         ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "#         print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_fillna(data):\n",
    "    # Get lengths of each row of data\n",
    "    lens = np.array([len(i) for i in data])\n",
    "\n",
    "    # Mask of valid places in each row\n",
    "    mask = np.arange(lens.max()) < lens[:,None]\n",
    "\n",
    "    # Setup output array and put elements from data into masked positions\n",
    "    out = np.zeros(mask.shape, dtype=data.dtype)\n",
    "    out[mask] = np.concatenate(data)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_encoded_sentances = numpy_fillna(encoded_sentances)\n",
    "input_mask = np.ones_like(padded_encoded_sentances)\n",
    "inputs_types = np.zeros(padded_encoded_sentances.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75118, 449)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_encoded_sentances.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75118, 449)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_types.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
