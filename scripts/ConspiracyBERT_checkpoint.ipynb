{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import collections\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from pymongo import MongoClient\n",
    "import urllib\n",
    "import multiprocess\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "# BERT files\n",
    "os.listdir(\"../bert-master\")\n",
    "sys.path.insert(0, '../bert-master')\n",
    "\n",
    "from run_classifier import *\n",
    "import modeling\n",
    "import optimization\n",
    "import tokenization\n",
    "\n",
    "import preprocessor as p\n",
    "\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "p.set_options(p.OPT.URL, p.OPT.EMOJI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data directories\n",
    "data_dir = './data'\n",
    "model_dir = './model'\n",
    "output_dir = './output'\n",
    "\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "    \n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    \n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = 'christian'\n",
    "password = 'Dec211996'\n",
    "\n",
    "client = MongoClient('mongodb://' + urllib.parse.quote_plus(username) + ':' + urllib.parse.quote_plus(password) + '@198.211.115.252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker(consp_tuple): \n",
    "    \n",
    "    ## this is temp\n",
    "    from pymongo import MongoClient\n",
    "    import urllib\n",
    "    import pickle\n",
    "    username = 'christian'\n",
    "    password = 'Dec211996'\n",
    "\n",
    "    client = MongoClient('mongodb://' + urllib.parse.quote_plus(username) + ':' + urllib.parse.quote_plus(password) + '@198.211.115.252')\n",
    "    \n",
    "    data_dir = './data'\n",
    "    ## end temp\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    conspiracy, hashtag = consp_tuple\n",
    "    cursor = client[conspiracy][hashtag].find({})\n",
    "    for i, document in enumerate(cursor):\n",
    "        try:\n",
    "            inputs = {'text' : p.clean(document['text'])}\n",
    "            inputs.update({'tweetId' : document['tweetId']})\n",
    "            data.append(inputs)\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "\n",
    "        if (i > 100):\n",
    "            break\n",
    "\n",
    "    with open(data_dir + '/' + conspiracy + '-' + hashtag + '.p', 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "    return consp_tuple\n",
    "\n",
    "def get_consp_tuples():\n",
    "    username = 'christian'\n",
    "    password = 'Dec211996'\n",
    "\n",
    "    client = MongoClient('mongodb://' + urllib.parse.quote_plus(username) + ':' + urllib.parse.quote_plus(password) + '@198.211.115.252')\n",
    "    \n",
    "    ignore_mask = ['test_db', 'admin', 'local', 'config', 'TwitterJobs']\n",
    "    conspiracies = list(set(client.list_database_names()) - set(ignore_mask))\n",
    "\n",
    "    consp_tuples = []\n",
    "    for conspiracy in conspiracies:\n",
    "        for hashtag in client[conspiracy].list_collection_names():\n",
    "            consp_tuples.append((conspiracy, hashtag))\n",
    "\n",
    "    return consp_tuples\n",
    "\n",
    "def preprocess():\n",
    "    consp_tuples = get_consp_tuples()\n",
    "    random.shuffle(consp_tuples)\n",
    "    p = multiprocess.Pool(multiprocess.cpu_count())\n",
    "#     consp_tuples = [(consp_tuple, data_dir) for consp_tuple in consp_tuples]\n",
    "#     results = p.map(worker, consp_tuples)\n",
    "\n",
    "    for i in range(10):\n",
    "        worker(consp_tuples[i])\n",
    "\n",
    "preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_labels():\n",
    "    conspiracies = set()\n",
    "    \n",
    "    for filename in os.listdir(data_dir):\n",
    "        if '.p' in filename:\n",
    "            conspiracies.add(filename.split('-')[0])\n",
    "    return {consp:i for i, consp in enumerate(conspiracies)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  dummy_1  target dummy_2  \\\n",
      "0              7290076266       4       *   \n",
      "1              7438885529       4       *   \n",
      "2              7478676096       4       *   \n",
      "3              7466879468       4       *   \n",
      "4              9391823778       4       *   \n",
      "...                   ...     ...     ...   \n",
      "2035  1271709878273392640       8       *   \n",
      "2036  1271638554079301632       8       *   \n",
      "2037  1273032402366091265       8       *   \n",
      "2038  1272979618346102784       8       *   \n",
      "2039  1272913869414023168       8       *   \n",
      "\n",
      "                                                   text  \n",
      "0     New Year Begins with Random Searches on the St...  \n",
      "1     #PRISONPLANET \"...contraband were #planted by ...  \n",
      "2     Alex Jones has 3 new protest #videos for 2010 ...  \n",
      "3     I do not believe I should give up my constitut...  \n",
      "4     RT @vivos2012: #prisonplanet leaks secret abou...  \n",
      "...                                                 ...  \n",
      "2035  A friend from London just sent me this! It see...  \n",
      "2036  2 billion doses of the Oxford coronavirus vacc...  \n",
      "2037  A good job persuading everyone they need a tox...  \n",
      "2038  #CoronaVirusUpdate #COVID19 #TestTraceIsolate ...  \n",
      "2039  Yeah... I was getting the \"official\" numbers f...  \n",
      "\n",
      "[2040 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "dummytext = '*'\n",
    "\n",
    "labels = generate_labels()\n",
    "\n",
    "for filename in os.listdir(data_dir):\n",
    "    if '.p' in filename:\n",
    "        with open(data_dir + '/' + filename, 'rb') as f:\n",
    "            consp = filename.split('-')[0]\n",
    "            x = pickle.load(f)\n",
    "            for row in x:\n",
    "                data.append({'dummy_1': row['tweetId'], 'target': labels[consp], 'dummy_2' : dummytext, 'text' : row['text']})\n",
    "df = pd.DataFrame(data)\n",
    "data = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# force train into cola format, test is fine as it is\n",
    "# train = train.sample(frac=0.01)\n",
    "# test = train.sample(frac=0.01)\n",
    "\n",
    "test_split = 0.2\n",
    "\n",
    "permuted_indices = list(np.random.permutation(len(df)))\n",
    "test_indices = random.sample(permuted_indices, int(len(permuted_indices) * test_split))\n",
    "train_indices = list(set(permuted_indices) - set(test_indices))\n",
    "\n",
    "train = df.iloc[train_indices]\n",
    "test = df.iloc[test_indices]\n",
    "\n",
    "train.to_csv(data_dir + '/train.tsv', sep='\\t', index=False, header=False)\n",
    "test.to_csv(data_dir + '/test.tsv', sep='\\t', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiClassColaProcessor(ColaProcessor):\n",
    "    def get_labels(self):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return list([str(x) for x in labels.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = 'cola'\n",
    "bert_config_file = model_dir + '/bert_config.json'\n",
    "vocab_file = model_dir + '/vocab.txt'\n",
    "init_checkpoint = model_dir + '/bert_model.ckpt'\n",
    "do_lower_case = True\n",
    "max_seq_length = 72\n",
    "do_train = True\n",
    "do_eval = False\n",
    "do_predict = False\n",
    "train_batch_size = 32\n",
    "eval_batch_size = 32\n",
    "predict_batch_size = 32\n",
    "learning_rate = 2e-5 \n",
    "num_train_epochs = 1.0\n",
    "warmup_proportion = 0.1\n",
    "use_tpu = False\n",
    "master = None\n",
    "save_checkpoints_steps = 99999999 # <----- don't want to save any checkpoints\n",
    "iterations_per_loop = 1000\n",
    "num_tpu_cores = 8\n",
    "tpu_cluster_resolver = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------\n",
      "Starting training ...\n",
      "--------------------------------------------------------\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From ../bert-master\\run_classifier.py:199: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x000002790498B5E8>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Using config: {'_model_dir': './output', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 99999999, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000027901A3B808>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': None}\n",
      "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
      "WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n",
      "WARNING:tensorflow:From ../bert-master\\run_classifier.py:483: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
      "\n",
      "WARNING:tensorflow:From ../bert-master\\run_classifier.py:487: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "INFO:tensorflow:Writing example 0 of 1632\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: train-0\n",
      "INFO:tensorflow:tokens: [CLS] new year begins with random searches on the streets of ny # prison ##plane ##t [SEP]\n",
      "INFO:tensorflow:input_ids: 101 2047 2095 4269 2007 6721 17193 2006 1996 4534 1997 6396 1001 3827 11751 2102 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 4 (id = 4)\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: train-1\n",
      "INFO:tensorflow:tokens: [CLS] \" # prison ##plane ##t \" \" . . . contra ##band were # planted by the authorities in the baggage of innocent passengers . . . \" \" # 1984 \" [SEP]\n",
      "INFO:tensorflow:input_ids: 101 1000 1001 3827 11751 2102 1000 1000 1012 1012 1012 24528 12733 2020 1001 8461 2011 1996 4614 1999 1996 20220 1997 7036 5467 1012 1012 1012 1000 1000 1001 3118 1000 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 4 (id = 4)\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: train-2\n",
      "INFO:tensorflow:tokens: [CLS] rt @ vivo ##s ##20 ##12 : # prison ##plane ##t leaks secret about # vivo ##s shelters . see [SEP]\n",
      "INFO:tensorflow:input_ids: 101 19387 1030 24269 2015 11387 12521 1024 1001 3827 11751 2102 29324 3595 2055 1001 24269 2015 17177 1012 2156 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 4 (id = 4)\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: train-3\n",
      "INFO:tensorflow:tokens: [CLS] # prison ##plane ##t leaks secret about # vivo ##s shelters . see [SEP]\n",
      "INFO:tensorflow:input_ids: 101 1001 3827 11751 2102 29324 3595 2055 1001 24269 2015 17177 1012 2156 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 4 (id = 4)\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: train-4\n",
      "INFO:tensorflow:tokens: [CLS] secret underground network of nuclear shelters for 3 , 600 co - owners . more : # prison ##plane ##t [SEP]\n",
      "INFO:tensorflow:input_ids: 101 3595 5230 2897 1997 4517 17177 2005 1017 1010 5174 2522 1011 5608 1012 2062 1024 1001 3827 11751 2102 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 4 (id = 4)\n",
      "INFO:tensorflow:***** Running training *****\n",
      "INFO:tensorflow:  Num examples = 1632\n",
      "INFO:tensorflow:  Batch size = 32\n",
      "INFO:tensorflow:  Num steps = 51\n",
      "WARNING:tensorflow:From ../bert-master\\run_classifier.py:514: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Ryan\\Anaconda3\\envs\\python37_env\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From C:\\Users\\Ryan\\Anaconda3\\envs\\python37_env\\lib\\site-packages\\tensorflow_core\\python\\training\\training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From ../bert-master\\run_classifier.py:550: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.map_and_batch(...)`.\n",
      "WARNING:tensorflow:From C:\\Users\\Ryan\\Anaconda3\\envs\\python37_env\\lib\\site-packages\\tensorflow_core\\contrib\\data\\python\\ops\\batching.py:276: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Ryan\\Anaconda3\\envs\\python37_env\\lib\\site-packages\\tensorflow_core\\python\\autograph\\converters\\directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
      "\n",
      "WARNING:tensorflow:From ../bert-master\\run_classifier.py:530: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Running train on CPU\n",
      "INFO:tensorflow:*** Features ***\n",
      "INFO:tensorflow:  name = input_ids, shape = (32, 72)\n",
      "INFO:tensorflow:  name = input_mask, shape = (32, 72)\n",
      "INFO:tensorflow:  name = is_real_example, shape = (32,)\n",
      "INFO:tensorflow:  name = label_ids, shape = (32,)\n",
      "INFO:tensorflow:  name = segment_ids, shape = (32, 72)\n",
      "WARNING:tensorflow:From ../bert-master\\modeling.py:171: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From ../bert-master\\modeling.py:409: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From ../bert-master\\modeling.py:490: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
      "\n",
      "WARNING:tensorflow:From ../bert-master\\modeling.py:358: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From ../bert-master\\modeling.py:671: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Ryan\\Anaconda3\\envs\\python37_env\\lib\\site-packages\\tensorflow_core\\python\\layers\\core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From ../bert-master\\run_classifier.py:647: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From ../bert-master\\run_classifier.py:661: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n",
      "\n",
      "INFO:tensorflow:**** Trainable Variables ****\n",
      "INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (30522, 128), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 128), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 128), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (128,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (128,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (128, 128), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (128,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (128, 128), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (128,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (128, 128), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (128,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (128, 128), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (128,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (128,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (128,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (128, 512), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (512,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (512, 128), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (128,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (128,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (128,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (128, 128), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (128,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (128, 128), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (128,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (128, 128), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (128,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (128, 128), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (128,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (128,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (128,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (128, 512), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (512,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (512, 128), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (128,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (128,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (128,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (128, 128), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (128,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = output_weights:0, shape = (10, 128)\n",
      "INFO:tensorflow:  name = output_bias:0, shape = (10,)\n",
      "WARNING:tensorflow:From ../bert-master\\optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
      "\n",
      "WARNING:tensorflow:From ../bert-master\\optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Ryan\\Anaconda3\\envs\\python37_env\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into ./output\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.68458\n",
      "INFO:tensorflow:examples/sec: 53.9064\n",
      "INFO:tensorflow:global_step/sec: 7.19653\n",
      "INFO:tensorflow:examples/sec: 230.289\n",
      "INFO:tensorflow:global_step/sec: 6.53804\n",
      "INFO:tensorflow:examples/sec: 209.217\n",
      "INFO:tensorflow:global_step/sec: 7.14512\n",
      "INFO:tensorflow:examples/sec: 228.644\n",
      "INFO:tensorflow:global_step/sec: 6.86188\n",
      "INFO:tensorflow:examples/sec: 219.58\n",
      "INFO:tensorflow:global_step/sec: 7.11937\n",
      "INFO:tensorflow:examples/sec: 227.82\n",
      "INFO:tensorflow:global_step/sec: 6.8515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 219.248\n",
      "INFO:tensorflow:global_step/sec: 6.02602\n",
      "INFO:tensorflow:examples/sec: 192.833\n",
      "INFO:tensorflow:global_step/sec: 6.71355\n",
      "INFO:tensorflow:examples/sec: 214.834\n",
      "INFO:tensorflow:global_step/sec: 4.23863\n",
      "INFO:tensorflow:examples/sec: 135.636\n",
      "INFO:tensorflow:global_step/sec: 6.89875\n",
      "INFO:tensorflow:examples/sec: 220.76\n",
      "INFO:tensorflow:global_step/sec: 5.86648\n",
      "INFO:tensorflow:examples/sec: 187.727\n",
      "INFO:tensorflow:global_step/sec: 6.06254\n",
      "INFO:tensorflow:examples/sec: 194.001\n",
      "INFO:tensorflow:global_step/sec: 7.3016\n",
      "INFO:tensorflow:examples/sec: 233.651\n",
      "INFO:tensorflow:global_step/sec: 7.09446\n",
      "INFO:tensorflow:examples/sec: 227.023\n",
      "INFO:tensorflow:global_step/sec: 6.62462\n",
      "INFO:tensorflow:examples/sec: 211.988\n",
      "INFO:tensorflow:global_step/sec: 6.06253\n",
      "INFO:tensorflow:examples/sec: 194.001\n",
      "INFO:tensorflow:global_step/sec: 7.17764\n",
      "INFO:tensorflow:examples/sec: 229.684\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 18 vs previous value: 18. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:global_step/sec: 5.76526\n",
      "INFO:tensorflow:examples/sec: 184.488\n",
      "INFO:tensorflow:global_step/sec: 6.13576\n",
      "INFO:tensorflow:examples/sec: 196.344\n",
      "INFO:tensorflow:global_step/sec: 7.46502\n",
      "INFO:tensorflow:examples/sec: 238.881\n",
      "INFO:tensorflow:global_step/sec: 7.30165\n",
      "INFO:tensorflow:examples/sec: 233.653\n",
      "INFO:tensorflow:global_step/sec: 7.3016\n",
      "INFO:tensorflow:examples/sec: 233.651\n",
      "INFO:tensorflow:global_step/sec: 7.30158\n",
      "INFO:tensorflow:examples/sec: 233.651\n",
      "INFO:tensorflow:global_step/sec: 7.43521\n",
      "INFO:tensorflow:examples/sec: 237.927\n",
      "INFO:tensorflow:global_step/sec: 7.19654\n",
      "INFO:tensorflow:examples/sec: 230.289\n",
      "INFO:tensorflow:global_step/sec: 6.99525\n",
      "INFO:tensorflow:examples/sec: 223.848\n",
      "INFO:tensorflow:global_step/sec: 6.7589\n",
      "INFO:tensorflow:examples/sec: 216.285\n",
      "INFO:tensorflow:global_step/sec: 7.69477\n",
      "INFO:tensorflow:examples/sec: 246.233\n",
      "INFO:tensorflow:global_step/sec: 7.35529\n",
      "INFO:tensorflow:examples/sec: 235.369\n",
      "INFO:tensorflow:global_step/sec: 7.52119\n",
      "INFO:tensorflow:examples/sec: 240.678\n",
      "INFO:tensorflow:global_step/sec: 8.00253\n",
      "INFO:tensorflow:examples/sec: 256.081\n",
      "INFO:tensorflow:global_step/sec: 7.97386\n",
      "INFO:tensorflow:examples/sec: 255.163\n",
      "INFO:tensorflow:global_step/sec: 7.87652\n",
      "INFO:tensorflow:examples/sec: 252.049\n",
      "INFO:tensorflow:global_step/sec: 6.94665\n",
      "INFO:tensorflow:examples/sec: 222.293\n",
      "INFO:tensorflow:global_step/sec: 6.99524\n",
      "INFO:tensorflow:examples/sec: 223.848\n",
      "INFO:tensorflow:global_step/sec: 7.3016\n",
      "INFO:tensorflow:examples/sec: 233.651\n",
      "INFO:tensorflow:global_step/sec: 8.13267\n",
      "INFO:tensorflow:examples/sec: 260.246\n",
      "INFO:tensorflow:global_step/sec: 8.0671\n",
      "INFO:tensorflow:examples/sec: 258.147\n",
      "INFO:tensorflow:global_step/sec: 7.22981\n",
      "INFO:tensorflow:examples/sec: 231.354\n",
      "INFO:tensorflow:global_step/sec: 7.63521\n",
      "INFO:tensorflow:examples/sec: 244.327\n",
      "INFO:tensorflow:global_step/sec: 7.35528\n",
      "INFO:tensorflow:examples/sec: 235.369\n",
      "INFO:tensorflow:global_step/sec: 7.87652\n",
      "INFO:tensorflow:examples/sec: 252.049\n",
      "INFO:tensorflow:global_step/sec: 7.46509\n",
      "INFO:tensorflow:examples/sec: 238.883\n",
      "INFO:tensorflow:global_step/sec: 7.81496\n",
      "INFO:tensorflow:examples/sec: 250.079\n",
      "INFO:tensorflow:global_step/sec: 8.33601\n",
      "INFO:tensorflow:examples/sec: 266.752\n",
      "INFO:tensorflow:global_step/sec: 7.24869\n",
      "INFO:tensorflow:examples/sec: 231.958\n",
      "INFO:tensorflow:global_step/sec: 7.84554\n",
      "INFO:tensorflow:examples/sec: 251.057\n",
      "INFO:tensorflow:global_step/sec: 7.87652\n",
      "INFO:tensorflow:examples/sec: 252.049\n",
      "INFO:tensorflow:global_step/sec: 7.5212\n",
      "INFO:tensorflow:examples/sec: 240.678\n",
      "INFO:tensorflow:Saving checkpoints for 51 into ./output\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 2.2503262.\n",
      "INFO:tensorflow:training_loop marked as finished\n",
      "--------------------------------------------------------\n",
      "Training complete in  31.513738870620728  seconds\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"--------------------------------------------------------\")\n",
    "print(\"Starting training ...\")\n",
    "print(\"--------------------------------------------------------\")\n",
    "\n",
    "bert_config = modeling.BertConfig.from_json_file(bert_config_file)\n",
    "\n",
    "processor = MultiClassColaProcessor()\n",
    "label_list = processor.get_labels()\n",
    "\n",
    "tokenizer = tokenization.FullTokenizer(vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
    "\n",
    "tpu_cluster_resolver = None\n",
    "is_per_host = tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2\n",
    "\n",
    "run_config = tf.contrib.tpu.RunConfig(\n",
    "  cluster=tpu_cluster_resolver,\n",
    "  master=master,\n",
    "  model_dir=output_dir,\n",
    "  save_checkpoints_steps=save_checkpoints_steps,\n",
    "  tpu_config=tf.contrib.tpu.TPUConfig(\n",
    "      iterations_per_loop=iterations_per_loop,\n",
    "      num_shards=num_tpu_cores,\n",
    "      per_host_input_for_training=is_per_host))\n",
    "\n",
    "train_examples = processor.get_train_examples(data_dir)\n",
    "num_train_steps = int(len(train_examples) / train_batch_size * num_train_epochs)\n",
    "num_warmup_steps = int(num_train_steps * warmup_proportion)\n",
    "\n",
    "model_fn = model_fn_builder(\n",
    "      bert_config=bert_config,\n",
    "      num_labels=len(label_list),\n",
    "      init_checkpoint=init_checkpoint,\n",
    "      learning_rate=learning_rate,\n",
    "      num_train_steps=num_train_steps,\n",
    "      num_warmup_steps=num_warmup_steps,\n",
    "      use_tpu=use_tpu,\n",
    "      use_one_hot_embeddings=use_tpu)\n",
    "\n",
    "estimator = tf.contrib.tpu.TPUEstimator(\n",
    "      use_tpu=use_tpu,\n",
    "      model_fn=model_fn,\n",
    "      config=run_config,\n",
    "      train_batch_size=train_batch_size)\n",
    "      \n",
    "      \n",
    "train_file = os.path.join(output_dir, \"train.tf_record\")\n",
    "\n",
    "file_based_convert_examples_to_features(\n",
    "    train_examples, label_list, max_seq_length, tokenizer, train_file)\n",
    "\n",
    "tf.logging.info(\"***** Running training *****\")\n",
    "tf.logging.info(\"  Num examples = %d\", len(train_examples))\n",
    "tf.logging.info(\"  Batch size = %d\", train_batch_size)\n",
    "tf.logging.info(\"  Num steps = %d\", num_train_steps)\n",
    "\n",
    "train_input_fn = file_based_input_fn_builder(\n",
    "    input_file=train_file,\n",
    "    seq_length=max_seq_length,\n",
    "    is_training=True,\n",
    "    drop_remainder=True)\n",
    "    \n",
    "estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
    "\n",
    "end = time.time()\n",
    "print(\"--------------------------------------------------------\")\n",
    "print(\"Training complete in \", end - start, \" seconds\")\n",
    "print(\"--------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_based_input_fn_builder(input_file, seq_length, is_training,\n",
    "                                drop_remainder):\n",
    "  \"\"\"Creates an `input_fn` closure to be passed to TPUEstimator.\"\"\"\n",
    "\n",
    "  name_to_features = {\n",
    "      \"input_ids\": tf.FixedLenFeature([seq_length], tf.int64),\n",
    "      \"input_mask\": tf.FixedLenFeature([seq_length], tf.int64),\n",
    "      \"segment_ids\": tf.FixedLenFeature([seq_length], tf.int64),\n",
    "      \"label_ids\": tf.FixedLenFeature([], tf.int64),\n",
    "      \"is_real_example\": tf.FixedLenFeature([], tf.int64),\n",
    "  }\n",
    "\n",
    "  def _decode_record(record, name_to_features):\n",
    "    \"\"\"Decodes a record to a TensorFlow example.\"\"\"\n",
    "    example = tf.parse_single_example(record, name_to_features)\n",
    "\n",
    "    # tf.Example only supports tf.int64, but the TPU only supports tf.int32.\n",
    "    # So cast all int64 to int32.\n",
    "    for name in list(example.keys()):\n",
    "      t = example[name]\n",
    "      if t.dtype == tf.int64:\n",
    "        t = tf.to_int32(t)\n",
    "      example[name] = t\n",
    "\n",
    "    return example\n",
    "\n",
    "  def input_fn(params):\n",
    "    \"\"\"The actual input function.\"\"\"\n",
    "    \n",
    "    #batch_size = params[\"batch_size\"]\n",
    "    batch_size = 64 # <----- hardcoded batch_size added here \n",
    "    \n",
    "    # For training, we want a lot of parallel reading and shuffling.\n",
    "    # For eval, we want no shuffling and parallel reading doesn't matter.\n",
    "    d = tf.data.TFRecordDataset(input_file)\n",
    "    if is_training:\n",
    "      d = d.repeat()\n",
    "      d = d.shuffle(buffer_size=100)\n",
    "\n",
    "    d = d.apply(\n",
    "        tf.contrib.data.map_and_batch(\n",
    "            lambda record: _decode_record(record, name_to_features),\n",
    "            batch_size=batch_size,\n",
    "            drop_remainder=drop_remainder))\n",
    "\n",
    "    return d\n",
    "\n",
    "  return input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------\n",
      "Starting inference ...\n",
      "--------------------------------------------------------\n",
      "INFO:tensorflow:Writing example 0 of 408\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: test-1\n",
      "INFO:tensorflow:tokens: [CLS] 4 [SEP]\n",
      "INFO:tensorflow:input_ids: 101 1018 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0 (id = 0)\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: test-2\n",
      "INFO:tensorflow:tokens: [CLS] 1 [SEP]\n",
      "INFO:tensorflow:input_ids: 101 1015 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0 (id = 0)\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: test-3\n",
      "INFO:tensorflow:tokens: [CLS] 0 [SEP]\n",
      "INFO:tensorflow:input_ids: 101 1014 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0 (id = 0)\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: test-4\n",
      "INFO:tensorflow:tokens: [CLS] 0 [SEP]\n",
      "INFO:tensorflow:input_ids: 101 1014 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0 (id = 0)\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: test-5\n",
      "INFO:tensorflow:tokens: [CLS] 0 [SEP]\n",
      "INFO:tensorflow:input_ids: 101 1014 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0 (id = 0)\n",
      "INFO:tensorflow:***** Running prediction*****\n",
      "INFO:tensorflow:  Num examples = 408 (408 actual, 0 padding)\n",
      "INFO:tensorflow:  Batch size = 32\n",
      "INFO:tensorflow:***** Predict results *****\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Running infer on CPU\n",
      "INFO:tensorflow:*** Features ***\n",
      "INFO:tensorflow:  name = input_ids, shape = (?, 72)\n",
      "INFO:tensorflow:  name = input_mask, shape = (?, 72)\n",
      "INFO:tensorflow:  name = is_real_example, shape = (?,)\n",
      "INFO:tensorflow:  name = label_ids, shape = (?,)\n",
      "INFO:tensorflow:  name = segment_ids, shape = (?, 72)\n",
      "INFO:tensorflow:**** Trainable Variables ****\n",
      "INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (30522, 128), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 128), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 128), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (128,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (128,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (128, 128), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (128,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (128, 128), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (128,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (128, 128), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (128,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (128, 128), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (128,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (128,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (128,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (128, 512), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (512,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (512, 128), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (128,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (128,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (128,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (128, 128), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (128,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (128, 128), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (128,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (128, 128), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (128,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (128, 128), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (128,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (128,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (128,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (128, 512), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (512,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (512, 128), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (128,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (128,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (128,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (128, 128), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (128,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = output_weights:0, shape = (10, 128)\n",
      "INFO:tensorflow:  name = output_bias:0, shape = (10,)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./output\\model.ckpt-51\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:prediction_loop marked as finished\n",
      "INFO:tensorflow:prediction_loop marked as finished\n",
      "--------------------------------------------------------\n",
      "Inference complete in  2.764305591583252  seconds\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"--------------------------------------------------------\")\n",
    "print(\"Starting inference ...\")\n",
    "print(\"--------------------------------------------------------\")\n",
    "\n",
    "predict_examples = processor.get_test_examples(data_dir)\n",
    "num_actual_predict_examples = len(predict_examples)\n",
    "\n",
    "predict_file = os.path.join(output_dir, \"predict.tf_record\")\n",
    "\n",
    "file_based_convert_examples_to_features(predict_examples, label_list,\n",
    "                                        max_seq_length, tokenizer,\n",
    "                                        predict_file)\n",
    "\n",
    "tf.logging.info(\"***** Running prediction*****\")\n",
    "tf.logging.info(\"  Num examples = %d (%d actual, %d padding)\",\n",
    "                len(predict_examples), num_actual_predict_examples,\n",
    "                len(predict_examples) - num_actual_predict_examples)\n",
    "tf.logging.info(\"  Batch size = %d\", predict_batch_size)\n",
    "\n",
    "predict_drop_remainder = True if use_tpu else False\n",
    "predict_input_fn = file_based_input_fn_builder(\n",
    "    input_file=predict_file,\n",
    "    seq_length=max_seq_length,\n",
    "    is_training=False,\n",
    "    drop_remainder=predict_drop_remainder)\n",
    "\n",
    "result = estimator.predict(input_fn=predict_input_fn)\n",
    "\n",
    "output_predict_file = os.path.join(output_dir, \"test_results.tsv\")\n",
    "\n",
    "with tf.gfile.GFile(output_predict_file, \"w\") as writer:\n",
    "    num_written_lines = 0\n",
    "    tf.logging.info(\"***** Predict results *****\")\n",
    "    for (i, prediction) in enumerate(result):\n",
    "        probabilities = prediction[\"probabilities\"]\n",
    "        if i >= num_actual_predict_examples:\n",
    "            break\n",
    "        output_line = \"\\t\".join(\n",
    "            str(class_probability)\n",
    "            for class_probability in probabilities) + \"\\n\"\n",
    "        writer.write(output_line)\n",
    "        num_written_lines += 1\n",
    "        \n",
    "end = time.time()\n",
    "print(\"--------------------------------------------------------\")\n",
    "print(\"Inference complete in \", end - start, \" seconds\")\n",
    "print(\"--------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'space': 0,\n",
       " 'nineeleven': 1,\n",
       " 'qanon': 2,\n",
       " 'epstein': 3,\n",
       " 'alexjones': 4,\n",
       " 'covid': 5,\n",
       " 'newworldorder': 6,\n",
       " 'clinton': 7,\n",
       " 'vaccines': 8,\n",
       " 'climate': 9}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
